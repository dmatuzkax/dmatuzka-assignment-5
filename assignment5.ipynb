{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fy8xR9OJtElz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jhnq1wrktEl0"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=5, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # TODO: Implement the fit method\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        # TODO: Implement the predict method\n",
        "        probabilities = []\n",
        "\n",
        "        distances = self.compute_distance(X, self.X_train)\n",
        "\n",
        "        # Iterate over each sample's distances\n",
        "        for dist in distances:\n",
        "            k_indices = np.argsort(dist)[:self.k]\n",
        "            k_nearest_labels = self.y_train[k_indices].astype(int)\n",
        "\n",
        "            prob_class_1 = np.sum(k_nearest_labels == 1) / self.k\n",
        "            probabilities.append(prob_class_1)\n",
        "\n",
        "        return np.array(probabilities)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((X1[:, np.newaxis] - X2)**2, axis=2))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X1[:, np.newaxis] - X2), axis=2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HDgYEHrltEl1"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    drop_cols = ['CustomerId', 'Surname']\n",
        "    train_data.drop(columns=drop_cols, inplace=True)\n",
        "    test_data.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train = train_data.drop('Exited', axis=1)\n",
        "    y_train = train_data['Exited']\n",
        "\n",
        "    # Reset index to avoid misalignment issues\n",
        "    X_train.reset_index(drop=True, inplace=True)\n",
        "    test_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Identify numerical and categorical columns\n",
        "    numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "    categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # --- Manually Scale Numerical Columns ---\n",
        "    def manual_robust_scaler(data):\n",
        "        median = np.median(data, axis=0)\n",
        "        q1 = np.percentile(data, 25, axis=0)\n",
        "        q3 = np.percentile(data, 75, axis=0)\n",
        "        iqr = q3 - q1\n",
        "        return (data - median) / (iqr + 1e-9)\n",
        "\n",
        "    # Apply scaling to numerical columns\n",
        "    X_train_num = manual_robust_scaler(X_train[numerical_cols].values)\n",
        "    X_test_num = manual_robust_scaler(test_data[numerical_cols].values)\n",
        "\n",
        "    # --- Manually One-Hot Encode Categorical Columns ---\n",
        "    def manual_one_hot_encoding(train, test):\n",
        "        train_encoded = []\n",
        "        test_encoded = []\n",
        "\n",
        "        for col in train.columns:\n",
        "            unique_vals = train[col].unique()\n",
        "            # Skip first category to avoid dummy variable\n",
        "            for val in unique_vals[1:]:\n",
        "                train_encoded.append((train[col] == val).astype(int))\n",
        "                test_encoded.append((test[col] == val).astype(int))\n",
        "\n",
        "        return np.column_stack(train_encoded), np.column_stack(test_encoded)\n",
        "\n",
        "    # Apply one-hot encoding to categorical columns\n",
        "    X_train_cat, X_test_cat = manual_one_hot_encoding(X_train[categorical_cols], test_data[categorical_cols])\n",
        "\n",
        "    # Concatenate numerical and categorical columns\n",
        "    X_train = np.hstack([X_train_num, X_train_cat])\n",
        "    X_test = np.hstack([X_test_num, X_test_cat])\n",
        "\n",
        "    return np.array(X_train), np.array(y_train), np.array(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WFhK5efXtEl1"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    fold_size = len(X) // n_splits\n",
        "    roc_auc_scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        # Create training and validation indices\n",
        "        val_start = i * fold_size\n",
        "        val_end = (i + 1) * fold_size if (i + 1) * fold_size < len(X) else len(X)\n",
        "\n",
        "        # Split the data into training and validation sets\n",
        "        X_train = np.concatenate((X[:val_start], X[val_end:]), axis=0)\n",
        "        y_train = np.concatenate((y[:val_start], y[val_end:]), axis=0)\n",
        "        X_val = X[val_start:val_end]\n",
        "        y_val = y[val_start:val_end]\n",
        "\n",
        "        # Train the model\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities on the validation set\n",
        "        y_pred_prob = knn.predict(X_val)\n",
        "\n",
        "        # Sort probabilities and true labels\n",
        "        sorted_indices = np.argsort(y_pred_prob)[::-1]\n",
        "        y_true_sorted = y_val[sorted_indices]\n",
        "        y_pred_sorted = y_pred_prob[sorted_indices]\n",
        "\n",
        "        # Calculate AUC using the trapezoidal rule\n",
        "        tp = 0  # True positives\n",
        "        fp = 0  # False positives\n",
        "        auc = 0.0\n",
        "        prev_tpr = 0  # Previous True Positive Rate\n",
        "        prev_fpr = 0  # Previous False Positive Rate\n",
        "\n",
        "        pos_count = np.sum(y_true_sorted)\n",
        "        total_negatives = len(y_true_sorted) - pos_count\n",
        "\n",
        "        for label in y_true_sorted:\n",
        "            if label == 1:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fp += 1\n",
        "                # Current True Positive Rate and False Positive Rate\n",
        "                tpr = tp / pos_count if pos_count > 0 else 0\n",
        "                fpr = fp / total_negatives if total_negatives > 0 else 0\n",
        "\n",
        "                # Incremental AUC calculation using the trapezoidal rule\n",
        "                auc += (fpr - prev_fpr) * (tpr + prev_tpr) / 2\n",
        "                prev_tpr = tpr\n",
        "                prev_fpr = fpr\n",
        "\n",
        "        # Handle the last point (final TPR and FPR)\n",
        "        tpr = tp / pos_count if pos_count > 0 else 0\n",
        "        fpr = fp / total_negatives if total_negatives > 0 else 0\n",
        "        auc += (fpr - prev_fpr) * (tpr + prev_tpr) / 2\n",
        "\n",
        "        # Store the computed AUC score for this fold\n",
        "        roc_auc_scores.append(auc)\n",
        "\n",
        "    return np.mean(roc_auc_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r3sZrcjUtEl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c514557c-4e05-4fb4-f29c-3b1edec89bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "k = 1, ROC-AUC: 0.7510\n",
            "k = 2, ROC-AUC: 0.8136\n",
            "k = 3, ROC-AUC: 0.8446\n",
            "k = 4, ROC-AUC: 0.8607\n",
            "k = 5, ROC-AUC: 0.8708\n",
            "k = 6, ROC-AUC: 0.8777\n",
            "k = 7, ROC-AUC: 0.8827\n",
            "k = 8, ROC-AUC: 0.8876\n",
            "k = 9, ROC-AUC: 0.8885\n",
            "k = 10, ROC-AUC: 0.8912\n",
            "k = 11, ROC-AUC: 0.8919\n",
            "k = 12, ROC-AUC: 0.8939\n",
            "k = 13, ROC-AUC: 0.8959\n",
            "k = 14, ROC-AUC: 0.8967\n",
            "k = 15, ROC-AUC: 0.8974\n",
            "k = 16, ROC-AUC: 0.8981\n",
            "k = 17, ROC-AUC: 0.8989\n",
            "k = 18, ROC-AUC: 0.8997\n",
            "k = 19, ROC-AUC: 0.9002\n",
            "k = 20, ROC-AUC: 0.9008\n",
            "k = 21, ROC-AUC: 0.9004\n",
            "k = 22, ROC-AUC: 0.9008\n",
            "k = 23, ROC-AUC: 0.9007\n",
            "k = 24, ROC-AUC: 0.9010\n",
            "k = 25, ROC-AUC: 0.9015\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "k_values = range(1, 26)\n",
        "roc_auc_scores = []\n",
        "\n",
        "# Perform cross-validation\n",
        "print(\"Cross-validation scores:\")\n",
        "for k in k_values:\n",
        "    knn = KNN(k=k, distance_metric='euclidean')\n",
        "    scores = cross_validate(X, y, knn, n_splits=5)\n",
        "    mean_score = np.mean(scores)\n",
        "    roc_auc_scores.append(mean_score)\n",
        "    print(f'k = {k}, ROC-AUC: {mean_score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hrhlY9FaCq8N"
      },
      "outputs": [],
      "source": [
        "# TODO: hyperparamters tuning\n",
        "best_k = k_values[np.argmax(roc_auc_scores)]\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric='euclidean')\n",
        "knn.fit(X, y)\n",
        "\n",
        "BATCH_SIZE = 1000\n",
        "\n",
        "test_predictions = []\n",
        "\n",
        "for i in range(0, len(X_test), BATCH_SIZE):\n",
        "    batch = X_test[i:i + BATCH_SIZE]\n",
        "    batch_predictions = knn.predict(batch)\n",
        "    test_predictions.extend(batch_predictions)\n",
        "\n",
        "test_predictions = np.array(test_predictions)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}