{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Fy8xR9OJtElz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jhnq1wrktEl0"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=5, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # TODO: Implement the fit method\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        # TODO: Implement the predict method\n",
        "        probabilities = []\n",
        "\n",
        "        distances = self.compute_distance(X, self.X_train)\n",
        "\n",
        "        # Iterate over each sample's distances\n",
        "        for dist in distances:\n",
        "            k_indices = np.argsort(dist)[:self.k]\n",
        "            k_nearest_labels = self.y_train[k_indices].astype(int)\n",
        "\n",
        "            prob_class_1 = np.sum(k_nearest_labels == 1) / self.k\n",
        "            probabilities.append(prob_class_1)\n",
        "\n",
        "        return np.array(probabilities)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((X1[:, np.newaxis] - X2)**2, axis=2))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X1[:, np.newaxis] - X2), axis=2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HDgYEHrltEl1"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    drop_cols = ['CustomerId', 'Surname']\n",
        "    train_data.drop(columns=drop_cols, inplace=True)\n",
        "    test_data.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train = train_data.drop('Exited', axis=1)\n",
        "    y_train = train_data['Exited']\n",
        "\n",
        "    # Reset index to avoid misalignment issues\n",
        "    X_train.reset_index(drop=True, inplace=True)\n",
        "    test_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Identify numerical and categorical columns\n",
        "    numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "    categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # --- Manually Scale Numerical Columns ---\n",
        "    def manual_robust_scaler(data):\n",
        "        median = np.median(data, axis=0)\n",
        "        q1 = np.percentile(data, 25, axis=0)\n",
        "        q3 = np.percentile(data, 75, axis=0)\n",
        "        iqr = q3 - q1\n",
        "        return (data - median) / (iqr + 1e-9)\n",
        "\n",
        "    # Apply scaling to numerical columns\n",
        "    X_train_num = manual_robust_scaler(X_train[numerical_cols].values)\n",
        "    X_test_num = manual_robust_scaler(test_data[numerical_cols].values)\n",
        "\n",
        "    # --- Manually One-Hot Encode Categorical Columns ---\n",
        "    def manual_one_hot_encoding(train, test):\n",
        "        train_encoded = []\n",
        "        test_encoded = []\n",
        "\n",
        "        for col in train.columns:\n",
        "            unique_vals = train[col].unique()\n",
        "            # Skip first category to avoid dummy variable\n",
        "            for val in unique_vals[1:]:\n",
        "                train_encoded.append((train[col] == val).astype(int))\n",
        "                test_encoded.append((test[col] == val).astype(int))\n",
        "\n",
        "        return np.column_stack(train_encoded), np.column_stack(test_encoded)\n",
        "\n",
        "    # Apply one-hot encoding to categorical columns\n",
        "    X_train_cat, X_test_cat = manual_one_hot_encoding(X_train[categorical_cols], test_data[categorical_cols])\n",
        "\n",
        "    # Concatenate numerical and categorical columns\n",
        "    X_train = np.hstack([X_train_num, X_train_cat])\n",
        "    X_test = np.hstack([X_test_num, X_test_cat])\n",
        "\n",
        "    return np.array(X_train), np.array(y_train), np.array(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WFhK5efXtEl1"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    fold_size = len(X) // n_splits\n",
        "    roc_auc_scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        # Create training and validation indices\n",
        "        val_start = i * fold_size\n",
        "        val_end = (i + 1) * fold_size if (i + 1) * fold_size < len(X) else len(X)\n",
        "\n",
        "        # Split the data into training and validation sets\n",
        "        X_train = np.concatenate((X[:val_start], X[val_end:]), axis=0)\n",
        "        y_train = np.concatenate((y[:val_start], y[val_end:]), axis=0)\n",
        "        X_val = X[val_start:val_end]\n",
        "        y_val = y[val_start:val_end]\n",
        "\n",
        "        # Train the model\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities on the validation set\n",
        "        y_pred_prob = knn.predict(X_val)\n",
        "\n",
        "        # Sort probabilities and true labels\n",
        "        sorted_indices = np.argsort(y_pred_prob)[::-1]\n",
        "        y_true_sorted = y_val[sorted_indices]\n",
        "        y_pred_sorted = y_pred_prob[sorted_indices]\n",
        "\n",
        "        # Calculate AUC using the trapezoidal rule\n",
        "        tp = 0  # True positives\n",
        "        fp = 0  # False positives\n",
        "        auc = 0.0\n",
        "        prev_tpr = 0  # Previous True Positive Rate\n",
        "        prev_fpr = 0  # Previous False Positive Rate\n",
        "\n",
        "        pos_count = np.sum(y_true_sorted)\n",
        "        total_negatives = len(y_true_sorted) - pos_count\n",
        "\n",
        "        for label in y_true_sorted:\n",
        "            if label == 1:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fp += 1\n",
        "                # Current True Positive Rate and False Positive Rate\n",
        "                tpr = tp / pos_count if pos_count > 0 else 0\n",
        "                fpr = fp / total_negatives if total_negatives > 0 else 0\n",
        "\n",
        "                # Incremental AUC calculation using the trapezoidal rule\n",
        "                auc += (fpr - prev_fpr) * (tpr + prev_tpr) / 2\n",
        "                prev_tpr = tpr\n",
        "                prev_fpr = fpr\n",
        "\n",
        "        # Handle the last point (final TPR and FPR)\n",
        "        tpr = tp / pos_count if pos_count > 0 else 0\n",
        "        fpr = fp / total_negatives if total_negatives > 0 else 0\n",
        "        auc += (fpr - prev_fpr) * (tpr + prev_tpr) / 2\n",
        "\n",
        "        # Store the computed AUC score for this fold\n",
        "        roc_auc_scores.append(auc)\n",
        "\n",
        "    return np.mean(roc_auc_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r3sZrcjUtEl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b5171a-7f4f-4340-80a0-b67703bce1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:\n",
            "k = 1, Euclidean ROC-AUC: 0.7510, Manhattan ROC-AUC: 0.7569\n",
            "k = 2, Euclidean ROC-AUC: 0.8136, Manhattan ROC-AUC: 0.8188\n",
            "k = 3, Euclidean ROC-AUC: 0.8446, Manhattan ROC-AUC: 0.8462\n",
            "k = 4, Euclidean ROC-AUC: 0.8607, Manhattan ROC-AUC: 0.8637\n",
            "k = 5, Euclidean ROC-AUC: 0.8708, Manhattan ROC-AUC: 0.8715\n",
            "k = 6, Euclidean ROC-AUC: 0.8777, Manhattan ROC-AUC: 0.8770\n",
            "k = 7, Euclidean ROC-AUC: 0.8827, Manhattan ROC-AUC: 0.8842\n",
            "k = 8, Euclidean ROC-AUC: 0.8876, Manhattan ROC-AUC: 0.8869\n",
            "k = 9, Euclidean ROC-AUC: 0.8885, Manhattan ROC-AUC: 0.8902\n",
            "k = 10, Euclidean ROC-AUC: 0.8912, Manhattan ROC-AUC: 0.8925\n",
            "k = 11, Euclidean ROC-AUC: 0.8919, Manhattan ROC-AUC: 0.8946\n",
            "k = 12, Euclidean ROC-AUC: 0.8939, Manhattan ROC-AUC: 0.8968\n",
            "k = 13, Euclidean ROC-AUC: 0.8959, Manhattan ROC-AUC: 0.8987\n",
            "k = 14, Euclidean ROC-AUC: 0.8967, Manhattan ROC-AUC: 0.8988\n",
            "k = 15, Euclidean ROC-AUC: 0.8974, Manhattan ROC-AUC: 0.8996\n",
            "k = 16, Euclidean ROC-AUC: 0.8981, Manhattan ROC-AUC: 0.9011\n",
            "k = 17, Euclidean ROC-AUC: 0.8989, Manhattan ROC-AUC: 0.9011\n",
            "k = 18, Euclidean ROC-AUC: 0.8997, Manhattan ROC-AUC: 0.9008\n",
            "k = 19, Euclidean ROC-AUC: 0.9002, Manhattan ROC-AUC: 0.9018\n",
            "k = 20, Euclidean ROC-AUC: 0.9008, Manhattan ROC-AUC: 0.9021\n",
            "k = 21, Euclidean ROC-AUC: 0.9004, Manhattan ROC-AUC: 0.9020\n",
            "k = 22, Euclidean ROC-AUC: 0.9008, Manhattan ROC-AUC: 0.9025\n",
            "k = 23, Euclidean ROC-AUC: 0.9007, Manhattan ROC-AUC: 0.9033\n",
            "k = 24, Euclidean ROC-AUC: 0.9010, Manhattan ROC-AUC: 0.9036\n",
            "k = 25, Euclidean ROC-AUC: 0.9015, Manhattan ROC-AUC: 0.9039\n",
            "k = 26, Euclidean ROC-AUC: 0.9015, Manhattan ROC-AUC: 0.9046\n",
            "k = 27, Euclidean ROC-AUC: 0.9027, Manhattan ROC-AUC: 0.9057\n",
            "k = 28, Euclidean ROC-AUC: 0.9031, Manhattan ROC-AUC: 0.9057\n",
            "k = 29, Euclidean ROC-AUC: 0.9026, Manhattan ROC-AUC: 0.9059\n",
            "k = 30, Euclidean ROC-AUC: 0.9036, Manhattan ROC-AUC: 0.9055\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "k_values = range(1, 31)\n",
        "roc_auc_scores_euclidean = []\n",
        "roc_auc_scores_manhattan = []\n",
        "\n",
        "# Perform cross-validation\n",
        "print(\"Cross-validation scores:\")\n",
        "for k in k_values:\n",
        "    # Evaluate with Euclidean distance\n",
        "    knn_euclidean = KNN(k=k, distance_metric='euclidean')\n",
        "    scores_euclidean = cross_validate(X, y, knn_euclidean, n_splits=5)\n",
        "    mean_score_euclidean = np.mean(scores_euclidean)\n",
        "    roc_auc_scores_euclidean.append(mean_score_euclidean)\n",
        "\n",
        "    # Evaluate with Manhattan distance\n",
        "    knn_manhattan = KNN(k=k, distance_metric='manhattan')\n",
        "    scores_manhattan = cross_validate(X, y, knn_manhattan, n_splits=5)\n",
        "    mean_score_manhattan = np.mean(scores_manhattan)\n",
        "    roc_auc_scores_manhattan.append(mean_score_manhattan)\n",
        "\n",
        "    # Print both scores in one line\n",
        "    print(f'k = {k}, Euclidean ROC-AUC: {mean_score_euclidean:.4f}, Manhattan ROC-AUC: {mean_score_manhattan:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hrhlY9FaCq8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b6e90d-6d85-4e7e-a1cf-50cc419da29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved into 'submissions.csv'\n"
          ]
        }
      ],
      "source": [
        "# TODO: hyperparamters tuning\n",
        "best_k_euclidean = k_values[np.argmax(roc_auc_scores_euclidean)]\n",
        "best_k_manhattan = k_values[np.argmax(roc_auc_scores_manhattan)]\n",
        "\n",
        "if roc_auc_scores_euclidean[np.argmax(roc_auc_scores_euclidean)] >= roc_auc_scores_manhattan[np.argmax(roc_auc_scores_manhattan)]:\n",
        "    best_k = best_k_euclidean\n",
        "    best_distance_metric = 'euclidean'\n",
        "else:\n",
        "    best_k = best_k_manhattan\n",
        "    best_distance_metric = 'manhattan'\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric='manhattan')\n",
        "knn.fit(X, y)\n",
        "\n",
        "BATCH_SIZE = 1000\n",
        "\n",
        "test_predictions = []\n",
        "\n",
        "for i in range(0, len(X_test), BATCH_SIZE):\n",
        "    batch = X_test[i:i + BATCH_SIZE]\n",
        "    batch_predictions = knn.predict(batch)\n",
        "    test_predictions.extend(batch_predictions)\n",
        "\n",
        "test_predictions = np.array(test_predictions)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)\n",
        "print(\"Predictions saved into \\'submissions.csv\\'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}